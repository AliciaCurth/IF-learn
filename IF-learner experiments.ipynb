{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments for IF-learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from paper_simulations.if_paper.helper_classes import RSmoothingSpline\n",
    "from paper_simulations.if_paper.if_learner_experiments import eval_range_n, eval_range_bias, eval_range_d\n",
    "from paper_simulations.if_paper.grf_experiments import eval_range_grf\n",
    "from iflearn.simulation_utils.base import constant_baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "range_n = [500, 1000, 3000, 5000, 10000, 30000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of train-samples: 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  38 tasks      | elapsed:    6.4s\n",
      "[Parallel(n_jobs=6)]: Done 188 tasks      | elapsed:   13.7s\n",
      "[Parallel(n_jobs=6)]: Done 438 tasks      | elapsed:   25.4s\n",
      "[Parallel(n_jobs=6)]: Done 500 out of 500 | elapsed:   28.0s finished\n",
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of train-samples: 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Done  38 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=6)]: Done 188 tasks      | elapsed:   10.8s\n",
      "[Parallel(n_jobs=6)]: Done 438 tasks      | elapsed:   24.9s\n",
      "[Parallel(n_jobs=6)]: Done 500 out of 500 | elapsed:   28.3s finished\n",
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of train-samples: 3000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Done  38 tasks      | elapsed:    4.8s\n",
      "[Parallel(n_jobs=6)]: Done 188 tasks      | elapsed:   27.4s\n",
      "[Parallel(n_jobs=6)]: Done 438 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=6)]: Done 500 out of 500 | elapsed:  1.3min finished\n",
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of train-samples: 5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Done  38 tasks      | elapsed:    8.0s\n",
      "[Parallel(n_jobs=6)]: Done 188 tasks      | elapsed:   40.1s\n",
      "[Parallel(n_jobs=6)]: Done 438 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=6)]: Done 500 out of 500 | elapsed:  1.8min finished\n",
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of train-samples: 10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Done  38 tasks      | elapsed:   16.7s\n",
      "[Parallel(n_jobs=6)]: Done 188 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=6)]: Done 438 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=6)]: Done 500 out of 500 | elapsed:  3.3min finished\n",
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of train-samples: 30000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Done  38 tasks      | elapsed:   47.0s\n",
      "[Parallel(n_jobs=6)]: Done 188 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=6)]: Done 438 tasks      | elapsed:  8.3min\n",
      "[Parallel(n_jobs=6)]: Done 500 out of 500 | elapsed:  9.4min finished\n"
     ]
    }
   ],
   "source": [
    "res_n = eval_range_n(RSmoothingSpline(), range_n,  n_jobs=6, \n",
    "                     verbose=1)\n",
    "res_n.to_csv('paper_simulations/if_paper/simulations/CATE_rangen_nobias.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRF experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def _nonlinear_effect_1(x):\n",
    "    return 1 + 1/(1+ np.exp((-20*(x-1/3))))\n",
    "\n",
    "def nonlinear_treatment_effect_1(X, dim_0=0, dim_1=1):\n",
    "    # example from Wager and Athey (2018)\n",
    "    return _nonlinear_effect_1(X[:, dim_0]) * _nonlinear_effect_1(X[:, dim_1])\n",
    "\n",
    "\n",
    "def normal_error_model(X, sd: float = 1, dim: int = 0):\n",
    "    \"\"\"\n",
    "    Generate errors according to N(0, sd)\n",
    "    Parameters\n",
    "    ----------\n",
    "    X: array-like\n",
    "        input data to use\n",
    "    dim: int, default 0\n",
    "        Dimension of X to use\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    An error value for each row of X\n",
    "    \"\"\"\n",
    "    return np.random.normal(0, sd, X.shape[0])\n",
    "\n",
    "\n",
    "def uniform_covariate_model(n: int, d: int = 1, low: float = 0, high: float = 1):\n",
    "    \"\"\"\n",
    "    Generate uniform covariates\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    n: int\n",
    "        number of observations to generate\n",
    "    d: int\n",
    "        number of dimensions\n",
    "    low: float\n",
    "        lower bound of hypercube\n",
    "    high: float\n",
    "        upper bound of hypercube\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np. array (n x d) with generated covariates\n",
    "    \"\"\"\n",
    "    return np.random.uniform(low=low, high=high, size=d * n).reshape(-1, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ambient dimension: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  38 tasks      | elapsed: 24.9min\n",
      "[Parallel(n_jobs=6)]: Done 188 tasks      | elapsed: 106.0min\n",
      "[Parallel(n_jobs=6)]: Done 200 out of 200 | elapsed: 110.6min finished\n"
     ]
    }
   ],
   "source": [
    "range_dim = [10]\n",
    "res_d = eval_range_grf(range_dim, dimension_range=True, propensity_model=None,\n",
    "                   repeats=200, covariate_model=uniform_covariate_model,\n",
    "                   n_test=1000, n_train=1600, d=1,\n",
    "                   te_function=nonlinear_treatment_effect_1, \n",
    "                    baseline_model=constant_baseline, error_model=normal_error_model,\n",
    "                   pre_dispatch='2*n_jobs', n_jobs=6, verbose=1)\n",
    "res_d.to_csv('paper_simulations/if_paper/simulations/GRFnew_nonlinear_train1600.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with confounding baseline and propensity \n",
    "from scipy.stats import beta\n",
    "def wa_baseline(X, dim: int = 2):\n",
    "    return 2*X[:, dim] - 1\n",
    "\n",
    "def wa_propensity(X, dim: int = 2):\n",
    "    return 0.25 * (beta.pdf(X[:, dim], 2, 4) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ambient dimension: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Done  38 tasks      | elapsed: 23.6min\n",
      "[Parallel(n_jobs=6)]: Done 188 tasks      | elapsed: 106.3min\n",
      "[Parallel(n_jobs=6)]: Done 200 out of 200 | elapsed: 111.0min finished\n"
     ]
    }
   ],
   "source": [
    "range_dim = [10]\n",
    "res_d = eval_range_grf(range_dim,  dimension_range=True, propensity_model=wa_propensity,\n",
    "                   repeats=200, covariate_model=uniform_covariate_model,\n",
    "                   n_test=1000, n_train=1600, d=1,\n",
    "                   te_function=None, \n",
    "                    baseline_model=wa_baseline, error_model=normal_error_model,\n",
    "                   n_jobs=6, verbose=1)\n",
    "res_d.to_csv('paper_simulations/if_paper/simulations/GRFnew_confounding_train1600.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ambient dimension: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Done  38 tasks      | elapsed: 23.0min\n",
      "[Parallel(n_jobs=6)]: Done 188 tasks      | elapsed: 104.6min\n",
      "[Parallel(n_jobs=6)]: Done 200 out of 200 | elapsed: 109.3min finished\n"
     ]
    }
   ],
   "source": [
    "range_dim = [10]\n",
    "res_d = eval_range_grf(range_dim,  dimension_range=True, propensity_model=wa_propensity,\n",
    "                   repeats=200, covariate_model=uniform_covariate_model,\n",
    "                   n_test=1000, n_train=1600, d=1,\n",
    "                   te_function=nonlinear_treatment_effect_1, \n",
    "                    baseline_model=wa_baseline, error_model=normal_error_model,\n",
    "                   n_jobs=6, verbose=1)\n",
    "res_d.to_csv('paper_simulations/if_paper/simulations/GRFnew_confoundingTE_train1600.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ambient dimension: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Done  38 tasks      | elapsed: 22.6min\n",
      "[Parallel(n_jobs=6)]: Done 188 tasks      | elapsed: 102.6min\n",
      "[Parallel(n_jobs=6)]: Done 200 out of 200 | elapsed: 107.1min finished\n"
     ]
    }
   ],
   "source": [
    "def te_wa_baseline_multiple(X, dim: int = 2):\n",
    "    return 3*(2*X[:, dim] - 1)\n",
    "range_dim = [10]\n",
    "res_d = eval_range_grf(range_dim,  dimension_range=True, propensity_model=wa_propensity,\n",
    "                   repeats=200, covariate_model=uniform_covariate_model,\n",
    "                   n_test=1000, n_train=1600, d=1,\n",
    "                   te_function=te_wa_baseline_multiple, \n",
    "                    baseline_model=wa_baseline, error_model=normal_error_model,\n",
    "                   n_jobs=6, verbose=1)\n",
    "res_d.to_csv('paper_simulations/if_paper/simulations/GRFnew_confoundingTEmultiple_train1600.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ambient dimension: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Done  38 tasks      | elapsed: 22.8min\n",
      "[Parallel(n_jobs=6)]: Done 188 tasks      | elapsed: 103.7min\n",
      "[Parallel(n_jobs=6)]: Done 200 out of 200 | elapsed: 108.3min finished\n"
     ]
    }
   ],
   "source": [
    "# have baseline supported on same covariates as te\n",
    "def wa_baseline(X, dim: int = 0):\n",
    "    return 2*X[:, dim] - 1\n",
    "\n",
    "def wa_propensity(X, dim: int = 0):\n",
    "    return 0.25 * (beta.pdf(X[:, dim], 2, 4) + 1)\n",
    "\n",
    "range_dim = [10]\n",
    "res_d = eval_range_grf(range_dim,  dimension_range=True, propensity_model=wa_propensity,\n",
    "                   repeats=200, covariate_model=uniform_covariate_model,\n",
    "                   n_test=1000, n_train=1600, d=1,\n",
    "                   te_function=nonlinear_treatment_effect_1, \n",
    "                    baseline_model=wa_baseline, error_model=normal_error_model,\n",
    "                   n_jobs=6, verbose=1)\n",
    "\n",
    "res_d.to_csv('paper_simulations/if_paper/simulations/GRFnew_confoundingTEsupport_train1600.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# heteroskedasticity\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
