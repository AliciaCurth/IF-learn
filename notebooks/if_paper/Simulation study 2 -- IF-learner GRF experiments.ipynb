{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments using GRF and IF-learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from paper_simulations.if_paper.grf_experiments import eval_range_grf\n",
    "from iflearn.simulation_utils.base import constant_baseline, baseline_wa, uniform_covariate_model,\\\n",
    "                                         normal_error_model, ModelCaller\n",
    "from iflearn.simulation_utils.treatment_effects import te_interaction_baseline, te_multiple_baseline,\\\n",
    "                                                        propensity_wa, nonlinear_treatment_effect_wa1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change defaults on uniform_covariate_model from [-1,1] to [0,1]\n",
    "unif_01 = ModelCaller(uniform_covariate_model, args={'high':1, 'low': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set which range of dimension to consider (here only d=10)\n",
    "range_dim = [10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ambient dimension: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:  9.0min\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed: 36.5min\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed: 37.8min finished\n"
     ]
    }
   ],
   "source": [
    "res_d = eval_range_grf(range_dim, dimension_range=True, propensity_model=None,\n",
    "                   repeats=200, covariate_model=unif_01,\n",
    "                   n_test=1000, n_train=800,\n",
    "                   te_function=nonlinear_treatment_effect_wa1, \n",
    "                   baseline_model=constant_baseline, error_model=normal_error_model,\n",
    "                   pre_dispatch='2*n_jobs', n_jobs=4, verbose=1)\n",
    "res_d.to_csv('paper_simulations/if_paper/simulations/GRF_nonlinearte_train800.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ambient dimension: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:  7.6min\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed: 31.1min\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed: 32.2min finished\n"
     ]
    }
   ],
   "source": [
    "res_d = eval_range_grf(range_dim,  dimension_range=True, propensity_model=propensity_wa,\n",
    "                       repeats=200, covariate_model=unif_01,\n",
    "                       n_test=1000, n_train=800,\n",
    "                       te_function=None, \n",
    "                       baseline_model=baseline_wa, error_model=normal_error_model,\n",
    "                       n_jobs=4, verbose=1)\n",
    "res_d.to_csv('paper_simulations/if_paper/simulations/GRF_confounding_train800.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ambient dimension: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:  7.0min\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed: 30.0min\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed: 31.2min finished\n"
     ]
    }
   ],
   "source": [
    "res_d = eval_range_grf(range_dim,  dimension_range=True, propensity_model=propensity_wa,\n",
    "                      repeats=200, covariate_model=unif_01,\n",
    "                      n_test=1000, n_train=800,\n",
    "                   te_function=nonlinear_treatment_effect_wa1, \n",
    "                    baseline_model=baseline_wa, error_model=normal_error_model,\n",
    "                   n_jobs=4, verbose=1)\n",
    "res_d.to_csv('paper_simulations/if_paper/simulations/GRF_confounding_nonlinearte_train800.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ambient dimension: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:  6.7min\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed: 29.0min\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed: 30.2min finished\n"
     ]
    }
   ],
   "source": [
    "res_d = eval_range_grf(range_dim,  dimension_range=True, propensity_model=propensity_wa,\n",
    "                       repeats=200, covariate_model=unif_01,\n",
    "                       n_test=1000, n_train=800, \n",
    "                       te_function=te_multiple_baseline, \n",
    "                       baseline_model=baseline_wa, error_model=normal_error_model,\n",
    "                       n_jobs=4, verbose=1)\n",
    "res_d.to_csv('paper_simulations/if_paper/simulations/GRF_confounding_temultiple_train800.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ambient dimension: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:  6.7min\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed: 29.3min\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed: 30.5min finished\n"
     ]
    }
   ],
   "source": [
    "res_d = eval_range_grf(range_dim,  dimension_range=True, propensity_model=propensity_wa,\n",
    "                      repeats=200, covariate_model=unif_01,\n",
    "                      n_test=1000, n_train=800,\n",
    "                      te_function=te_interaction_baseline, \n",
    "                      baseline_model=baseline_wa, error_model=normal_error_model,\n",
    "                      n_jobs=4, verbose=1)\n",
    "res_d.to_csv('paper_simulations/if_paper/simulations/GRFnew_confounding_teinteraction_train800.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
