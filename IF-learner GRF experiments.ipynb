{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments using GRF and IF-learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from paper_simulations.if_paper.grf_experiments import eval_range_grf\n",
    "from iflearn.simulation_utils.base import constant_baseline, baseline_wa, uniform_covariate_model,\\\n",
    "                                         normal_error_model, ModelCaller\n",
    "from iflearn.simulation_utils.treatment_effects import te_interaction_baseline, te_multiple_baseline,\\\n",
    "                                                        propensity_wa, nonlinear_treatment_effect_wa1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change defaults on uniform_covariate_model from [-1,1] to [0,1]\n",
    "unif_01 = ModelCaller(uniform_covariate_model, args={'high':1, 'low': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set which range of dimension to consider (here only d=10)\n",
    "range_dim = [10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ambient dimension: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    }
   ],
   "source": [
    "res_d = eval_range_grf(range_dim, dimension_range=True, propensity_model=None,\n",
    "                   repeats=200, covariate_model=unif_01,\n",
    "                   n_test=1000, n_train=800,\n",
    "                   te_function=nonlinear_treatment_effect_wa1, \n",
    "                   baseline_model=constant_baseline, error_model=normal_error_model,\n",
    "                   pre_dispatch='2*n_jobs', n_jobs=4, verbose=1)\n",
    "res_d.to_csv('paper_simulations/if_paper/simulations/GRF_nonlinearte_train800.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_d = eval_range_grf(range_dim,  dimension_range=True, propensity_model=propensity_wa,\n",
    "                       repeats=200, covariate_model=unif_01,\n",
    "                       n_test=1000, n_train=800,\n",
    "                       te_function=None, \n",
    "                       baseline_model=baseline_wa, error_model=normal_error_model,\n",
    "                       n_jobs=4, verbose=1)\n",
    "res_d.to_csv('paper_simulations/if_paper/simulations/GRF_confounding_train800.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_d = eval_range_grf(range_dim,  dimension_range=True, propensity_model=propensity_wa,\n",
    "                      repeats=200, covariate_model=unif_01,\n",
    "                      n_test=1000, n_train=800,\n",
    "                   te_function=nonlinear_treatment_effect_wa1, \n",
    "                    baseline_model=baseline_wa, error_model=normal_error_model,\n",
    "                   n_jobs=4, verbose=1)\n",
    "res_d.to_csv('paper_simulations/if_paper/simulations/GRF_confounding_nonlinearte_train800.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_d = eval_range_grf(range_dim,  dimension_range=True, propensity_model=propensity_wa,\n",
    "                       repeats=200, covariate_model=unif_01,\n",
    "                       n_test=1000, n_train=800, \n",
    "                       te_function=te_multiple_baseline, \n",
    "                       baseline_model=baseline_wa, error_model=normal_error_model,\n",
    "                       n_jobs=4, verbose=1)\n",
    "res_d.to_csv('paper_simulations/if_paper/simulations/GRF_confounding_temultiple_train800.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_d = eval_range_grf(range_dim,  dimension_range=True, propensity_model=propensity_wa,\n",
    "                      repeats=200, covariate_model=unif_01,\n",
    "                      n_test=1000, n_train=800,\n",
    "                      te_function=te_interaction_baseline, \n",
    "                      baseline_model=baseline_wa, error_model=normal_error_model,\n",
    "                      n_jobs=4, verbose=1)\n",
    "res_d.to_csv('paper_simulations/if_paper/simulations/GRFnew_confounding_teinteraction_train800.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "range_dim = [10]\n",
    "# with confounding baseline and propensity \n",
    "from scipy.stats import beta\n",
    "def wa_baseline(X, dim: int = 2):\n",
    "    return 2*X[:, dim] - 1\n",
    "\n",
    "def wa_propensity(X, dim: int = 2):\n",
    "    return 0.25 * (beta.pdf(X[:, dim], 2, 4) + 1)\n",
    "\n",
    "def te_wa_baseline_multiple(X, dim: int = 2):\n",
    "    return nonlinear_treatment_effect_1(X)*wa_baseline(X)\n",
    "res_d = eval_range_grf(range_dim,  dimension_range=True, propensity_model=wa_propensity,\n",
    "                   repeats=200, covariate_model=uniform_covariate_model,\n",
    "                   n_test=1000, n_train=1600, d=1,\n",
    "                   te_function=te_wa_baseline_multiple, \n",
    "                    baseline_model=wa_baseline, error_model=normal_error_model,\n",
    "                   n_jobs=3, verbose=1)\n",
    "res_d.to_csv('paper_simulations/if_paper/simulations/GRFnew_confoundingTEmultiplenonlin_train1600.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "range_dim = [10]\n",
    "# with confounding baseline and propensity \n",
    "from scipy.stats import beta\n",
    "def wa_baseline(X, dim: int = 2):\n",
    "    return 2*X[:, dim] - 1\n",
    "\n",
    "def wa_propensity(X, dim: int = 2):\n",
    "    return 0.25 * (beta.pdf(X[:, dim], 2, 4) + 1)\n",
    "\n",
    "def te_wa_baseline_multiple(X, dim: int = 2):\n",
    "    return 3*(2*X[:, dim] - 1)\n",
    "res_d = eval_range_grf(range_dim,  dimension_range=True, propensity_model=wa_propensity,\n",
    "                   repeats=200, covariate_model=uniform_covariate_model,\n",
    "                   n_test=1000, n_train=800, d=1,\n",
    "                   te_function=te_wa_baseline_multiple, \n",
    "                    baseline_model=wa_baseline, error_model=normal_error_model,\n",
    "                   n_jobs=4, verbose=1)\n",
    "res_d.to_csv('paper_simulations/if_paper/simulations/GRFnew_confoundingTEmultiple_train800.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# have baseline supported on same covariates as te\n",
    "def wa_baseline(X, dim: int = 0):\n",
    "    return 2*X[:, dim] - 1\n",
    "\n",
    "def wa_propensity(X, dim: int = 0):\n",
    "    return 0.25 * (beta.pdf(X[:, dim], 2, 4) + 1)\n",
    "\n",
    "range_dim = [10]\n",
    "res_d = eval_range_grf(range_dim,  dimension_range=True, propensity_model=wa_propensity,\n",
    "                   repeats=200, covariate_model=uniform_covariate_model,\n",
    "                   n_test=1000, n_train=1600, d=1,\n",
    "                   te_function=nonlinear_treatment_effect_1, \n",
    "                    baseline_model=wa_baseline, error_model=normal_error_model,\n",
    "                   n_jobs=4, verbose=1)\n",
    "\n",
    "res_d.to_csv('paper_simulations/if_paper/simulations/GRFnew_confoundingTEsupport_train1600.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# have baseline supported on same covariates as te\n",
    "def wa_baseline(X, dim: int = 0):\n",
    "    return 2*X[:, dim] - 1\n",
    "\n",
    "def wa_propensity(X, dim: int = 0):\n",
    "    return 0.25 * (beta.pdf(X[:, dim], 2, 4) + 1)\n",
    "range_dim = [10]\n",
    "res_d = eval_range_grf(range_dim,  dimension_range=True, propensity_model=wa_propensity,\n",
    "                   repeats=200, covariate_model=uniform_covariate_model,\n",
    "                   n_test=1000, n_train=3200, d=1,\n",
    "                   te_function=nonlinear_treatment_effect_1, \n",
    "                    baseline_model=wa_baseline, error_model=normal_error_model,\n",
    "                   n_jobs=4, verbose=1)\n",
    "\n",
    "res_d.to_csv('paper_simulations/if_paper/simulations/GRFnew_confoundingTEsupport_train3200.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# heteroskedasticity\n",
    "def cos_error_model(X, dim: int = 3):\n",
    "    return np.random.normal(0, 1 - 0.75 * np.cos(2 * np.pi * X[:, dim]), X.shape[0])\n",
    "\n",
    "range_dim = [10]\n",
    "# with confounding baseline and propensity \n",
    "from scipy.stats import beta\n",
    "def wa_baseline(X, dim: int = 2):\n",
    "    return 2*X[:, dim] - 1\n",
    "\n",
    "def wa_propensity(X, dim: int = 2):\n",
    "    return 0.25 * (beta.pdf(X[:, dim], 2, 4) + 1)\n",
    "res_d = eval_range_grf(range_dim,  dimension_range=True, propensity_model=wa_propensity,\n",
    "                   repeats=200, covariate_model=uniform_covariate_model,\n",
    "                   n_test=1000, n_train=800, d=1,\n",
    "                   te_function=None, \n",
    "                   baseline_model=wa_baseline, error_model=cos_error_model,\n",
    "                   n_jobs=3, verbose=1)\n",
    "res_d.to_csv('paper_simulations/if_paper/simulations/GRFnew_confoundinghetero3_train800.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# heteroskedasticity\n",
    "def cos_error_model(X, dim: int = 3):\n",
    "    return np.random.normal(0, 1 - 0.75 * np.cos(2 * np.pi * X[:, dim]), X.shape[0])\n",
    "\n",
    "range_dim = [10]\n",
    "# with confounding baseline and propensity \n",
    "from scipy.stats import beta\n",
    "def wa_baseline(X, dim: int = 2):\n",
    "    return 2*X[:, dim] - 1\n",
    "\n",
    "def wa_propensity(X, dim: int = 2):\n",
    "    return 0.25 * (beta.pdf(X[:, dim], 2, 4) + 1)\n",
    "res_d = eval_range_grf(range_dim,  dimension_range=True, propensity_model=wa_propensity,\n",
    "                   repeats=200, covariate_model=uniform_covariate_model,\n",
    "                   n_test=1000, n_train=1600, d=1,\n",
    "                   te_function=None, \n",
    "                   baseline_model=wa_baseline, error_model=cos_error_model,\n",
    "                   n_jobs=4, verbose=1)\n",
    "res_d.to_csv('paper_simulations/if_paper/simulations/GRFnew_confoundinghetero3_train1600.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# heteroskedasticity\n",
    "def cos_error_model(X, dim: int = 2):\n",
    "    return np.random.normal(0, 1 - 0.75 * np.cos(2 * np.pi * X[:, dim]), X.shape[0])\n",
    "\n",
    "range_dim = [10]\n",
    "# with confounding baseline and propensity \n",
    "from scipy.stats import beta\n",
    "def wa_baseline(X, dim: int = 2):\n",
    "    return 2*X[:, dim] - 1\n",
    "\n",
    "def wa_propensity(X, dim: int = 2):\n",
    "    return 0.25 * (beta.pdf(X[:, dim], 2, 4) + 1)\n",
    "res_d = eval_range_grf(range_dim,  dimension_range=True, propensity_model=wa_propensity,\n",
    "                   repeats=200, covariate_model=uniform_covariate_model,\n",
    "                   n_test=1000, n_train=800, d=1,\n",
    "                   te_function=None, \n",
    "                   baseline_model=wa_baseline, error_model=cos_error_model,\n",
    "                   n_jobs=4, verbose=1)\n",
    "res_d.to_csv('paper_simulations/if_paper/simulations/GRFnew_confoundinghetero2_train800.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# heteroskedasticity\n",
    "def cos_error_model(X, dim: int = 2):\n",
    "    return np.random.normal(0, 1 - 0.75 * np.cos(2 * np.pi * X[:, dim]), X.shape[0])\n",
    "\n",
    "range_dim = [10]\n",
    "# with confounding baseline and propensity \n",
    "from scipy.stats import beta\n",
    "def wa_baseline(X, dim: int = 2):\n",
    "    return 2*X[:, dim] - 1\n",
    "\n",
    "def wa_propensity(X, dim: int = 2):\n",
    "    return 0.25 * (beta.pdf(X[:, dim], 2, 4) + 1)\n",
    "res_d = eval_range_grf(range_dim,  dimension_range=True, propensity_model=wa_propensity,\n",
    "                   repeats=200, covariate_model=uniform_covariate_model,\n",
    "                   n_test=1000, n_train=1600, d=1,\n",
    "                   te_function=None, \n",
    "                   baseline_model=wa_baseline, error_model=cos_error_model,\n",
    "                   n_jobs=4, verbose=1)\n",
    "res_d.to_csv('paper_simulations/if_paper/simulations/GRFnew_confoundinghetero2_train1600.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
