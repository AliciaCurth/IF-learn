{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulation studies\n",
    "This notebook allows to replicate the simulation studies in Curth, Alaa and van der Schaar (2020). Note: it requires a working installation of rpy2.\n",
    "\n",
    "## Simulation study 1\n",
    "Simulation studies using one dimensional data based on the motivating example of Kennedy (2020). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_JOBS = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_REPEATS_SIM1 = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The IF-learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make directories for saving\n",
    "IF_PATH = 'paper_utils/if_paper/paper_results/if-learner/'\n",
    "import os \n",
    "if not os.path.exists(IF_PATH):\n",
    "    os.makedirs(IF_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from paper_utils.if_paper.helper_classes import RSmoothingSpline, AdaptiveLogisticGAM\n",
    "from paper_utils.if_paper.if_learner_experiments import eval_range_bias, eval_range_n\n",
    "\n",
    "from iflearn.simulation_utils.base import binary_gyorfi_baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set range of training observations to consider\n",
    "range_n = [200, 500, 1000, 2000, 3000, 5000, 10000, 30000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Constant propensity (p=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_n = eval_range_n(RSmoothingSpline(), range_n, repeats=N_REPEATS_SIM1, n_jobs=N_JOBS, \n",
    "                     verbose=1)\n",
    "res_n.to_csv(IF_PATH + 'CATE_spline_p05.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of train-samples: 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    7.4s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:   14.6s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:   27.3s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:   30.4s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of train-samples: 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:   12.6s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:   30.6s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:   34.7s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of train-samples: 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    4.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:   17.4s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:   39.6s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:   44.3s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of train-samples: 2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    5.4s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:   26.9s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:  1.1min finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of train-samples: 3000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    8.4s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:   37.3s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:  1.6min finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of train-samples: 5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:   13.1s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:  2.7min finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of train-samples: 10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:   29.3s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:  4.7min\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:  5.3min finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of train-samples: 30000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:  5.5min\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed: 10.6min\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed: 11.8min finished\n"
     ]
    }
   ],
   "source": [
    "res_n = eval_range_n(RSmoothingSpline(), range_n, repeats=N_REPEATS_SIM1, n_jobs=N_JOBS, \n",
    "                     verbose=1, setting='PO1')\n",
    "res_n.to_csv(IF_PATH + 'PO1_spline_p05.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_n = eval_range_n(AdaptiveLogisticGAM(), range_n, repeats=N_REPEATS_SIM1, n_jobs=N_JOBS, \n",
    "                     baseline_model=binary_gyorfi_baseline, setting='RR',\n",
    "                     verbose=1, binary_y=True,  te_estimator=RSmoothingSpline())\n",
    "res_n.to_csv(IF_PATH + 'RR_gam_p05.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Propensity score from Kennedy (2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from iflearn.simulation_utils.treatment_effects import propensity_kennedy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_n = eval_range_n(RSmoothingSpline(), range_n, repeats=N_REPEATS_SIM1,n_jobs=N_JOBS, \n",
    "                     verbose=1, propensity_model=propensity_kennedy)\n",
    "res_n.to_csv(IF_PATH + 'CATE_spline_withpropensity.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of train-samples: 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  76 tasks      | elapsed:    2.7s\n",
      "[Parallel(n_jobs=4)]: Done 376 tasks      | elapsed:   12.6s\n",
      "[Parallel(n_jobs=4)]: Done 493 out of 500 | elapsed:   16.4s remaining:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:   16.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of train-samples: 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  76 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=4)]: Done 376 tasks      | elapsed:   17.4s\n",
      "[Parallel(n_jobs=4)]: Done 493 out of 500 | elapsed:   24.2s remaining:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:   24.5s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of train-samples: 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:   10.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:   23.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:   25.9s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of train-samples: 2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:   15.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:   36.1s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:   40.8s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of train-samples: 3000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    6.2s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:   24.5s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:   56.2s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:  1.1min finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of train-samples: 5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    8.6s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:   38.2s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:  1.7min finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of train-samples: 10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:   19.4s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:  3.4min finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of train-samples: 30000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:   51.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:  3.7min\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:  8.6min\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:  9.7min finished\n"
     ]
    }
   ],
   "source": [
    "res_n = eval_range_n(RSmoothingSpline(), range_n, repeats=N_REPEATS_SIM1,n_jobs=N_JOBS, \n",
    "                     verbose=1, propensity_model=propensity_kennedy, setting='PO1')\n",
    "res_n.to_csv(IF_PATH + 'PO1_spline_withpropensity.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_n = eval_range_n(AdaptiveLogisticGAM(), range_n, repeats=N_REPEATS_SIM1, \n",
    "                    n_jobs=N_JOBS,  setting='RR',\n",
    "                     propensity_model=propensity_kennedy,\n",
    "                     baseline_model=binary_gyorfi_baseline,\n",
    "                     verbose=1, binary_y=True, te_estimator=RSmoothingSpline())\n",
    "res_n.to_csv(IF_PATH + 'RR_gam_withpropensity.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unknown selection bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "range_b =  [p for p in np.arange(0.1, 1, 0.05)] \n",
    "res_b = eval_range_bias(RSmoothingSpline(), range_b, repeats=N_REPEATS_SIM1, \n",
    "                        n_jobs=N_JOBS, verbose=1, n_train=500)\n",
    "res_b.to_csv(IF_PATH + 'CATE_spline_withbias.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bias with parameter: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    4.9s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:   11.1s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:   22.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:   24.3s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bias with parameter: 0.15000000000000002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  76 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=4)]: Done 376 tasks      | elapsed:   14.6s\n",
      "[Parallel(n_jobs=4)]: Done 493 out of 500 | elapsed:   19.2s remaining:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:   19.4s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bias with parameter: 0.20000000000000004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  76 tasks      | elapsed:    2.9s\n",
      "[Parallel(n_jobs=4)]: Done 376 tasks      | elapsed:   14.5s\n",
      "[Parallel(n_jobs=4)]: Done 493 out of 500 | elapsed:   19.2s remaining:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:   19.3s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bias with parameter: 0.25000000000000006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  76 tasks      | elapsed:    2.9s\n",
      "[Parallel(n_jobs=4)]: Done 376 tasks      | elapsed:   14.6s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:   19.3s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bias with parameter: 0.30000000000000004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  76 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=4)]: Done 376 tasks      | elapsed:   14.6s\n",
      "[Parallel(n_jobs=4)]: Done 493 out of 500 | elapsed:   19.1s remaining:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:   19.2s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bias with parameter: 0.3500000000000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  76 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=4)]: Done 376 tasks      | elapsed:   14.6s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:   19.4s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bias with parameter: 0.40000000000000013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  76 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=4)]: Done 376 tasks      | elapsed:   14.5s\n",
      "[Parallel(n_jobs=4)]: Done 493 out of 500 | elapsed:   18.9s remaining:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:   19.1s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bias with parameter: 0.45000000000000007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  76 tasks      | elapsed:    2.9s\n",
      "[Parallel(n_jobs=4)]: Done 376 tasks      | elapsed:   14.4s\n",
      "[Parallel(n_jobs=4)]: Done 493 out of 500 | elapsed:   18.9s remaining:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:   19.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bias with parameter: 0.5000000000000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  76 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=4)]: Done 376 tasks      | elapsed:   14.5s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:   19.2s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bias with parameter: 0.5500000000000002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  76 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=4)]: Done 376 tasks      | elapsed:   14.9s\n",
      "[Parallel(n_jobs=4)]: Done 493 out of 500 | elapsed:   19.4s remaining:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:   19.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bias with parameter: 0.6000000000000002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  76 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=4)]: Done 376 tasks      | elapsed:   14.4s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:   19.0s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bias with parameter: 0.6500000000000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  76 tasks      | elapsed:    2.9s\n",
      "[Parallel(n_jobs=4)]: Done 376 tasks      | elapsed:   14.5s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:   19.5s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bias with parameter: 0.7000000000000002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  76 tasks      | elapsed:    2.9s\n",
      "[Parallel(n_jobs=4)]: Done 376 tasks      | elapsed:   14.5s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:   19.2s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bias with parameter: 0.7500000000000002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  76 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=4)]: Done 376 tasks      | elapsed:   14.3s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:   19.1s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bias with parameter: 0.8000000000000002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  76 tasks      | elapsed:    2.9s\n",
      "[Parallel(n_jobs=4)]: Done 376 tasks      | elapsed:   14.4s\n",
      "[Parallel(n_jobs=4)]: Done 493 out of 500 | elapsed:   18.9s remaining:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:   19.0s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bias with parameter: 0.8500000000000002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  76 tasks      | elapsed:    2.9s\n",
      "[Parallel(n_jobs=4)]: Done 376 tasks      | elapsed:   15.1s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:   20.3s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bias with parameter: 0.9000000000000002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  76 tasks      | elapsed:    3.5s\n",
      "[Parallel(n_jobs=4)]: Done 376 tasks      | elapsed:   16.4s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:   21.1s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bias with parameter: 0.9500000000000003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  76 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=4)]: Done 376 tasks      | elapsed:   15.5s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:   20.9s finished\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "range_b =  [p for p in np.arange(0.1, 1, 0.05)] \n",
    "res_b = eval_range_bias(RSmoothingSpline(), range_b, repeats=N_REPEATS_SIM1, \n",
    "                        n_jobs=N_JOBS, verbose=1, n_train=500, setting='PO1')\n",
    "res_b.to_csv(IF_PATH + 'PO1_spline_withbias.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Group-IF-learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make directories for saving\n",
    "GROUP_PATH = 'paper_utils/if_paper/paper_results/group-if-learner/'\n",
    "import os \n",
    "if not os.path.exists(GROUP_PATH):\n",
    "    os.makedirs(GROUP_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from paper_utils.if_paper.group_if_learner_experiments import eval_range_n_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "range_n = [100, 200, 500, 750, 1000, 2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment not in paper\n",
    "res_n = eval_range_n_group(RSmoothingSpline(), range_n, repeats=N_REPEATS_SIM1, n_jobs=N_JOBS, \n",
    "                     verbose=1)\n",
    "res_n.to_csv(GROUP_PATH + 'CATE_spline_p05_group.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment in paper\n",
    "res_n = eval_range_n_group(RSmoothingSpline(), range_n, repeats=N_REPEATS_SIM1, n_jobs=N_JOBS, \n",
    "                     verbose=1, propensity_model=propensity_kennedy)\n",
    "res_n.to_csv(GROUP_PATH + 'CATE_spline_withpropensity_group.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation study 2: GRFs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make directories for saving\n",
    "GRF_PATH = 'paper_utils/if_paper/paper_results/grf-if-learner/'\n",
    "import os \n",
    "if not os.path.exists(GRF_PATH):\n",
    "    os.makedirs(GRF_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from paper_utils.if_paper.grf_experiments import eval_range_grf\n",
    "\n",
    "from iflearn.simulation_utils.base import constant_baseline, baseline_wa, uniform_covariate_model,\\\n",
    "                                         normal_error_model, ModelCaller\n",
    "from iflearn.simulation_utils.treatment_effects import te_interaction_baseline, te_multiple_baseline,\\\n",
    "                                                        propensity_wa, nonlinear_treatment_effect_wa1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_REPEATS_SIM2 = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change defaults on uniform_covariate_model from [-1,1] to [0,1]\n",
    "unif_01 = ModelCaller(uniform_covariate_model, args={'high':1, 'low': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "range_n = [800, 1600]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_n = eval_range_grf(range_n, dimension_range=False, propensity_model=None,\n",
    "                   repeats=N_REPEATS_SIM2, covariate_model=unif_01,\n",
    "                   n_test=1000, d=10,\n",
    "                   te_function=nonlinear_treatment_effect_wa1, \n",
    "                   baseline_model=constant_baseline, error_model=normal_error_model,\n",
    "                   pre_dispatch='2*n_jobs', n_jobs=N_JOBS, verbose=1)\n",
    "res_n.to_csv(GRF_PATH + 'GRF_nonlinearTE_noconfounding.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_n = eval_range_grf(range_n,  dimension_range=False, propensity_model=propensity_wa,\n",
    "                       repeats=N_REPEATS_SIM2, covariate_model=unif_01,\n",
    "                       n_test=1000,  d=10,\n",
    "                       te_function=None, \n",
    "                       baseline_model=baseline_wa, error_model=normal_error_model,\n",
    "                       n_jobs=N_JOBS, verbose=1)\n",
    "res_n.to_csv(GRF_PATH + 'GRF_noTE_confounding.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_n = eval_range_grf(range_n, dimension_range=False, propensity_model=propensity_wa,\n",
    "                      repeats=N_REPEATS_SIM2, covariate_model=unif_01,\n",
    "                      n_test=1000, d=10,\n",
    "                      te_function=nonlinear_treatment_effect_wa1, \n",
    "                    baseline_model=baseline_wa, error_model=normal_error_model,\n",
    "                   n_jobs=N_JOBS, verbose=1)\n",
    "res_n.to_csv(GRF_PATH + 'GRF_nonlinearTE_confounding.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_n = eval_range_grf(range_n,  dimension_range=False, propensity_model=propensity_wa,\n",
    "                       repeats=N_REPEATS_SIM2, covariate_model=unif_01,\n",
    "                       n_test=1000, d=10,\n",
    "                       te_function=te_multiple_baseline, \n",
    "                       baseline_model=baseline_wa, error_model=normal_error_model,\n",
    "                       n_jobs=N_JOBS, verbose=1)\n",
    "res_n.to_csv(GRF_PATH + 'GRF_multipleTE_confounding.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_n = eval_range_grf(range_n,  dimension_range=False, propensity_model=propensity_wa,\n",
    "                      repeats=N_REPEATS_SIM2, covariate_model=unif_01,\n",
    "                      n_test=1000, d=10,\n",
    "                      te_function=te_interaction_baseline, \n",
    "                      baseline_model=baseline_wa, error_model=normal_error_model,\n",
    "                      n_jobs=N_JOBS, verbose=1)\n",
    "res_n.to_csv(GRF_PATH + 'GRF_interactionTE_confounding.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dissenv]",
   "language": "python",
   "name": "conda-env-dissenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
