{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulation studies\n",
    "This notebook allows to replicate the simulation studies in Curth, Alaa and van der Schaar (2020). Note: it requires a working installation of rpy2.\n",
    "\n",
    "## Simulation study 1\n",
    "Simulation studies using one dimensional data based on the motivating example of Kennedy (2020). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_JOBS = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_REPEATS_SIM1 = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The IF-learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make directories for saving\n",
    "IF_PATH = 'paper_utils/if_paper/paper_results/if-learner/'\n",
    "import os \n",
    "if not os.path.exists(IF_PATH):\n",
    "    os.makedirs(IF_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from paper_utils.if_paper.helper_classes import RSmoothingSpline, AdaptiveLogisticGAM\n",
    "from paper_utils.if_paper.if_learner_experiments import eval_range_bias, eval_range_n\n",
    "\n",
    "from iflearn.simulation_utils.base import binary_gyorfi_baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set range of training observations to consider\n",
    "range_n = [200, 500, 1000, 2000, 3000, 5000, 10000, 30000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Constant propensity (p=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of train-samples: 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    4.9s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    9.5s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:   18.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:   19.6s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of train-samples: 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  76 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=4)]: Done 376 tasks      | elapsed:   15.3s\n",
      "[Parallel(n_jobs=4)]: Done 493 out of 500 | elapsed:   20.4s remaining:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:   20.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of train-samples: 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    9.3s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:   25.4s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:   28.6s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of train-samples: 2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:   14.9s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:   34.9s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:   39.5s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of train-samples: 3000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    5.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:   22.6s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:   51.4s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:   57.5s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of train-samples: 5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    8.8s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:   39.3s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:  1.6min finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of train-samples: 10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:   16.8s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:  2.9min finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of train-samples: 30000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:   45.1s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:  7.6min\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:  8.6min finished\n"
     ]
    }
   ],
   "source": [
    "res_n = eval_range_n(RSmoothingSpline(), range_n, repeats=N_REPEATS_SIM1, n_jobs=N_JOBS, \n",
    "                     verbose=1)\n",
    "res_n.to_csv(IF_PATH + 'CATE_spline_p05.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "C:\\Users\\alici\\Anaconda3\\envs\\dissenv\\lib\\site-packages\\sklearn\\base.py:197: FutureWarning: From version 0.24, get_params will raise an AttributeError if a parameter cannot be retrieved as an instance attribute. Previously it would return None.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of train-samples: 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:   47.7s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:  3.4min\n"
     ]
    }
   ],
   "source": [
    "res_n = eval_range_n(AdaptiveLogisticGAM(), range_n, repeats=N_REPEATS_SIM1, n_jobs=N_JOBS, \n",
    "                     baseline_model=binary_gyorfi_baseline, setting='RR',\n",
    "                     verbose=1, binary_y=True,  te_estimator=RSmoothingSpline())\n",
    "res_n.to_csv(IF_PATH + 'RR_gam_p05.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Propensity score from Kennedy (2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from iflearn.simulation_utils.treatment_effects import propensity_kennedy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_n = eval_range_n(RSmoothingSpline(), range_n, repeats=N_REPEATS_SIM1,n_jobs=N_JOBS, \n",
    "                     verbose=1, propensity_model=propensity_kennedy)\n",
    "res_n.to_csv(IF_PATH + 'CATE_spline_withpropensity.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_n = eval_range_n(AdaptiveLogisticGAM(), range_n, repeats=N_REPEATS_SIM1, \n",
    "                    n_jobs=N_JOBS,  setting='RR',\n",
    "                     propensity_model=propensity_kennedy,\n",
    "                     baseline_model=binary_gyorfi_baseline,\n",
    "                     verbose=1, binary_y=True, te_estimator=RSmoothingSpline())\n",
    "res_n.to_csv(IF_PATH + 'RR_gam_withpropensity.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unknown selection bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "range_b =  [p for p in np.arange(0.1, 1, 0.05)] \n",
    "res_b = eval_range_bias(RSmoothingSpline(), range_b, repeats=N_REPEATS_SIM1, \n",
    "                        n_jobs=N_JOBS, verbose=1, n_train=500)\n",
    "res_b.to_csv(IF_PATH + 'CATE_spline_withbias.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Group-IF-learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make directories for saving\n",
    "GROUP_PATH = 'paper_utils/if_paper/paper_results/group-if-learner/'\n",
    "import os \n",
    "if not os.path.exists(GROUP_PATH):\n",
    "    os.makedirs(GROUP_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from paper_utils.if_paper.group_if_learner_experiments import eval_range_n_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "range_n = [100, 200, 500, 750, 1000, 2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment not in paper\n",
    "res_n = eval_range_n_group(RSmoothingSpline(), range_n, repeats=N_REPEATS_SIM1, n_jobs=N_JOBS, \n",
    "                     verbose=1)\n",
    "res_n.to_csv(GROUP_PATH + 'CATE_spline_p05_group.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment in paper\n",
    "res_n = eval_range_n_group(RSmoothingSpline(), range_n, repeats=N_REPEATS_SIM1, n_jobs=N_JOBS, \n",
    "                     verbose=1, propensity_model=propensity_kennedy)\n",
    "res_n.to_csv(GROUP_PATH + 'CATE_spline_withpropensity_group.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation study 2: GRFs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make directories for saving\n",
    "GRF_PATH = 'paper_utils/if_paper/paper_results/grf-if-learner/'\n",
    "import os \n",
    "if not os.path.exists(GRF_PATH):\n",
    "    os.makedirs(GRF_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from paper_utils.if_paper.grf_experiments import eval_range_grf\n",
    "\n",
    "from iflearn.simulation_utils.base import constant_baseline, baseline_wa, uniform_covariate_model,\\\n",
    "                                         normal_error_model, ModelCaller\n",
    "from iflearn.simulation_utils.treatment_effects import te_interaction_baseline, te_multiple_baseline,\\\n",
    "                                                        propensity_wa, nonlinear_treatment_effect_wa1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_REPEATS_SIM2 = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change defaults on uniform_covariate_model from [-1,1] to [0,1]\n",
    "unif_01 = ModelCaller(uniform_covariate_model, args={'high':1, 'low': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "range_n = [800, 1600]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_n = eval_range_grf(range_n, dimension_range=False, propensity_model=None,\n",
    "                   repeats=N_REPEATS_SIM2, covariate_model=unif_01,\n",
    "                   n_test=1000, d=10,\n",
    "                   te_function=nonlinear_treatment_effect_wa1, \n",
    "                   baseline_model=constant_baseline, error_model=normal_error_model,\n",
    "                   pre_dispatch='2*n_jobs', n_jobs=N_JOBS, verbose=1)\n",
    "res_n.to_csv(GRF_PATH + 'GRF_nonlinearTE_noconfounding.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_n = eval_range_grf(range_n,  dimension_range=False, propensity_model=propensity_wa,\n",
    "                       repeats=N_REPEATS_SIM2, covariate_model=unif_01,\n",
    "                       n_test=1000,  d=10,\n",
    "                       te_function=None, \n",
    "                       baseline_model=baseline_wa, error_model=normal_error_model,\n",
    "                       n_jobs=N_JOBS, verbose=1)\n",
    "res_n.to_csv(GRF_PATH + 'GRF_noTE_confounding.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_n = eval_range_grf(range_n, dimension_range=False, propensity_model=propensity_wa,\n",
    "                      repeats=N_REPEATS_SIM2, covariate_model=unif_01,\n",
    "                      n_test=1000, d=10,\n",
    "                      te_function=nonlinear_treatment_effect_wa1, \n",
    "                    baseline_model=baseline_wa, error_model=normal_error_model,\n",
    "                   n_jobs=N_JOBS, verbose=1)\n",
    "res_n.to_csv(GRF_PATH + 'GRF_nonlinearTE_confounding.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_n = eval_range_grf(range_n,  dimension_range=False, propensity_model=propensity_wa,\n",
    "                       repeats=N_REPEATS_SIM2, covariate_model=unif_01,\n",
    "                       n_test=1000, d=10,\n",
    "                       te_function=te_multiple_baseline, \n",
    "                       baseline_model=baseline_wa, error_model=normal_error_model,\n",
    "                       n_jobs=N_JOBS, verbose=1)\n",
    "res_n.to_csv(GRF_PATH + 'GRF_multipleTE_confounding.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_n = eval_range_grf(range_n,  dimension_range=False, propensity_model=propensity_wa,\n",
    "                      repeats=N_REPEATS_SIM2, covariate_model=unif_01,\n",
    "                      n_test=1000, d=10,\n",
    "                      te_function=te_interaction_baseline, \n",
    "                      baseline_model=baseline_wa, error_model=normal_error_model,\n",
    "                      n_jobs=N_JOBS, verbose=1)\n",
    "res_n.to_csv(GRF_PATH + 'GRF_interactionTE_confounding.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
